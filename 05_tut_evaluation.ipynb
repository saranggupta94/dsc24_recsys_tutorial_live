{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e12cbca-e05b-4e41-8c0a-4d48fd4079c6",
   "metadata": {},
   "source": [
    "### Evaluation Metrics for Recommender Systems\n",
    "\n",
    "### Error-based Metrics\n",
    "\n",
    "### Root Mean Square Error (RMSE)\n",
    "RMSE is one of the most popular metrics for evaluating the accuracy of predicted ratings in recommender systems. It emphasizes larger errors by squaring them before taking the mean, making it particularly sensitive to outliers.\n",
    "\n",
    "The formula for RMSE is:\n",
    "\n",
    "$$\n",
    "RMSE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(x_i - \\hat{x_i})^2}\n",
    "$$\n",
    "\n",
    "\n",
    "### Mean Absolute Error (MAE)\n",
    "MAE measures the average magnitude of errors without considering their direction. Unlike RMSE, it treats all errors on a linear scale.\n",
    "\n",
    "$$\n",
    "MAE = \\frac{1}{N}\\sum_{i=1}^{N}|x_i - \\hat{x_i}|\n",
    "$$\n",
    "\n",
    "## Ranking-based Metrics\n",
    "\n",
    "### Precision\n",
    "Precision measures the proportion of relevant items among all recommended items:\n",
    "\n",
    "$$\n",
    "Precision@k = \\frac{\\text{number of relevant items @k}}{\\text{total number of recommended items @k}}\n",
    "$$\n",
    "\n",
    "### Recall\n",
    "Recall measures the proportion of relevant items that were successfully recommended:\n",
    "\n",
    "$$\n",
    "Recall@k = \\frac{\\text{number of relevant items @k}}{\\text{total number of relevant items}}\n",
    "$$\n",
    "\n",
    "### Normalized Discounted Cumulative Gain (NDCG)\n",
    "NDCG measures the quality of ranking by considering both the relevance and position of recommendations. It penalizes highly relevant items appearing lower in the recommendation list.\n",
    "\n",
    "$$\n",
    "DCG@k = \\sum_{i=1}^k \\frac{2^{rel_i} - 1}{\\log_2(i + 1)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "NDCG@k = \\frac{DCG@k}{IDCG@k}\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$rel_i \\text{: the relevance score of item at position i}$$\n",
    "$$IDCG@k \\text{: the DCG@k of the ideal ranking}$$\n",
    "\n",
    "### Coverage and Diversity Metrics\n",
    "\n",
    "### Catalog Coverage\n",
    "Measures the percentage of items that the system is able to recommend:\n",
    "\n",
    "$$\n",
    "Coverage = \\frac{\\text{number of items that can be recommended}}{\\text{total number of items}} \\times 100\\%\n",
    "$$\n",
    "\n",
    "### User Coverage\n",
    "Measures the percentage of users for whom the system can make recommendations:\n",
    "\n",
    "$$\n",
    "User Coverage = \\frac{\\text{number of users who receive recommendations}}{\\text{total number of users}} \\times 100\\%\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a5c24b-80e7-4f0e-b70c-f4b1e2fa00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import _______  # Exercise: Import cosine_similarity\n",
    "from sklearn.decomposition import _______ # Exercise: Import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df70a4c-61d4-4622-94a8-32974320cf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('data-1m/ratings.csv', \n",
    "                         sep='\\t',\n",
    "                         encoding='latin-1',\n",
    "                         engine='python',\n",
    "                         index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aaeba4-f32e-4994-a966-a3a5b853e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random sample\n",
    "sample_size = 100000\n",
    "ratings_sample = ratings_df.sample(n=sample_size, random_state=42)\n",
    "\n",
    "# Split the data \n",
    "train_data, test_data = train_test_split(\n",
    "    ratings_sample, \n",
    "    test_size=____, # Exercise: Fill in test size\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create rating matrix for training\n",
    "rating_matrix = train_data.pivot(\n",
    "    index='_______', //Exercise: fill in index\n",
    "    columns='_______', # Exercise: Fill in columns\n",
    "    values='_______' # Exercise: Fill in values\n",
    ")\n",
    "\n",
    "# Fill NaN with mean rating for each movie\n",
    "movie_means = rating_matrix._______() # Exercise: Compute mean\n",
    "rating_matrix = rating_matrix.fillna(_______) # Exercise: Fill NaN with movie_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facc9c3-aa2a-49e6-aafd-44ebb80949ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_useruser(user_id, movie_id, rating_matrix, user_sim, n_neighbors=5):\n",
    "    if user_id not in rating_matrix.index or movie_id not in rating_matrix.columns:\n",
    "        return None\n",
    "        \n",
    "    user_idx = rating_matrix.index.get_loc(user_id)\n",
    "    sim_scores = user_sim[user_idx]\n",
    "    \n",
    "    movie_ratings = rating_matrix[movie_id]\n",
    "    rated_mask = movie_ratings > 0\n",
    "    \n",
    "    if not rated_mask.any():\n",
    "        return None\n",
    "        \n",
    "    sim_users = sim_scores[rated_mask]\n",
    "    ratings = movie_ratings[rated_mask]\n",
    "    \n",
    "    top_indices = np.argsort(sim_users)[-n_neighbors:]\n",
    "    weights = sim_users[top_indices]\n",
    "    \n",
    "    if weights.sum() == 0:\n",
    "        return None\n",
    "        \n",
    "    pred = np.average(ratings.iloc[top_indices], weights=weights)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e484e-b09e-4e3a-9a25-323db7a2512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-User CF\n",
    "user_sim = _______(_______) # Exercise: Calculate cosine similarity\n",
    "\n",
    "# NMF\n",
    "nmf = NMF(\n",
    "    n_components=15, # Exercise: Experiment with different values\n",
    "    init='nndsvd',\n",
    "    solver='cd',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit NMF model\n",
    "W = nmf._______(_______) # Exercise: Fit the model\n",
    "H = nmf._______ # Exercise: Get components_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b176b24-080c-45c4-90b6-f5edaf7d84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions...\")\n",
    "uu_predictions = []\n",
    "nmf_predictions = []\n",
    "actuals = []\n",
    "\n",
    "for _, row in test_data.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    movie_id = row['movie_id']\n",
    "    actual_rating = row['rating']\n",
    "    \n",
    "    # Skip if user or movie not in training data\n",
    "    if user_id not in rating_matrix.index or movie_id not in rating_matrix.columns:\n",
    "        continue\n",
    "        \n",
    "    # User-User CF prediction\n",
    "    uu_pred = predict_rating_useruser(user_id, movie_id, rating_matrix, user_sim)\n",
    "    \n",
    "    # NMF prediction\n",
    "    if uu_pred is not None:\n",
    "        user_idx = rating_matrix.index.get_loc(user_id)\n",
    "        movie_idx = rating_matrix.columns.get_loc(movie_id)\n",
    "        \n",
    "        # Compute NMF prediction\n",
    "        nmf_pred = W[user_idx].dot(H[:, movie_idx])\n",
    "        \n",
    "        # Clip to valid rating range\n",
    "        nmf_pred = np.clip(nmf_pred, 1, 5)\n",
    "        \n",
    "        uu_predictions.append(uu_pred)\n",
    "        nmf_predictions.append(nmf_pred)\n",
    "        actuals.append(actual_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728e0c2c-cb75-4245-8bf6-108b9158699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE\n",
    "uu_rmse = np.sqrt(_______(_______, _______)) # Exercise: Calculate RMSE\n",
    "nmf_rmse = np.sqrt(_______(_______, _______))  # Exercise: Calculate RMSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
